{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = vocab.union(set(['yes', 'no']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1  #one extra for keras pad-sequences placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LONGEST STORY\n",
    "all_story_lengths = [len(data[0]) for data in all_data]\n",
    "\n",
    "# LONGEST QUESTION\n",
    "all_ques_lengths = [len(data[1]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ques_len = max(all_ques_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ques_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])  # default fiter is not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 35, 20, 16, 1, 33, 3, 10, 26, 20, 5, 33], [22, 3, 13, 20, 32, 29], [23]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(all_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'there': 1,\n",
       " 'hallway': 2,\n",
       " 'john': 3,\n",
       " 'bathroom': 4,\n",
       " 'bedroom': 5,\n",
       " 'mary': 6,\n",
       " 'office': 7,\n",
       " 'went': 8,\n",
       " 'picked': 9,\n",
       " 'moved': 10,\n",
       " 'dropped': 11,\n",
       " 'discarded': 12,\n",
       " 'in': 13,\n",
       " 'took': 14,\n",
       " 'back': 15,\n",
       " 'milk': 16,\n",
       " 'grabbed': 17,\n",
       " 'down': 18,\n",
       " 'apple': 19,\n",
       " 'the': 20,\n",
       " 'yes': 21,\n",
       " 'is': 22,\n",
       " 'no': 23,\n",
       " 'football': 24,\n",
       " 'up': 25,\n",
       " 'to': 26,\n",
       " 'journeyed': 27,\n",
       " 'sandra': 28,\n",
       " '?': 29,\n",
       " 'left': 30,\n",
       " 'garden': 31,\n",
       " 'kitchen': 32,\n",
       " '.': 33,\n",
       " 'put': 34,\n",
       " 'got': 35,\n",
       " 'daniel': 36,\n",
       " 'travelled': 37}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_ques_len=max_ques_len):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_ques_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 20,  5, 33],\n",
       "       [ 0,  0,  0, ..., 20,  2, 33],\n",
       "       [ 0,  0,  0, ..., 20,  4, 33],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 20,  5, 33],\n",
       "       [ 0,  0,  0, ..., 16,  1, 33],\n",
       "       [ 0,  0,  0, ..., 19,  1, 33]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,\n",
       "          0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.]), 1000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test), len(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense, LSTM, Input, Activation, Permute, Dropout, add, dot, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLCEHOLDER shape=(max_story_len, batch_size)\n",
    "input_sequence = Input((max_story_len, ))\n",
    "question = Input((max_ques_len, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME AS vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kokat\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\kokat\\.conda\\envs\\nlp_course\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, max_len_story, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_ques_len))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, max_len_story, max_ques_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION ENCODER\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# OUTPUT\n",
    "# (samples, max_len_story, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <--- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'sequential_3/dropout_2/cond/Merge:0' shape=(?, 156, 64) dtype=float32>,\n",
       " <tf.Tensor 'sequential_6/dropout_3/cond/Merge:0' shape=(?, 6, 64) dtype=float32>,\n",
       " <tf.Tensor 'sequential_5/embedding_2/embedding_lookup/Identity:0' shape=(?, 156, 6) dtype=float32>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoded_m, question_encoded, input_encoded_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating match between m (Embedding A) and q (Embedding B)\n",
    "\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_1/truediv:0' shape=(?, 156, 6) dtype=float32>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([input_encoded_c, match])\n",
    "response = Permute((2, 1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'permute_1/transpose:0' shape=(?, 6, 156) dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dense(vocab_size)(answer) # (samples, vocab_size) YES/NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       multiple             2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_3[3][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       multiple             228         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           sequential_5[3][0]               \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kokat\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kokat\\.conda\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.8191 - acc: 0.4975 - val_loss: 0.6940 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.6950 - acc: 0.4974 - val_loss: 0.7211 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 8s 783us/step - loss: 0.6955 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.4830\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 8s 785us/step - loss: 0.6948 - acc: 0.5051 - val_loss: 0.6942 - val_acc: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 8s 789us/step - loss: 0.6953 - acc: 0.4951 - val_loss: 0.6936 - val_acc: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 8s 789us/step - loss: 0.6951 - acc: 0.5012 - val_loss: 0.6935 - val_acc: 0.5030\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 8s 781us/step - loss: 0.6945 - acc: 0.5109 - val_loss: 0.6937 - val_acc: 0.5020\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.6936 - acc: 0.5088 - val_loss: 0.6978 - val_acc: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.6912 - acc: 0.5295 - val_loss: 0.6914 - val_acc: 0.5280\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 8s 781us/step - loss: 0.6782 - acc: 0.5703 - val_loss: 0.6734 - val_acc: 0.5760\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 8s 777us/step - loss: 0.6081 - acc: 0.6792 - val_loss: 0.5797 - val_acc: 0.7030\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 8s 781us/step - loss: 0.5229 - acc: 0.7538 - val_loss: 0.4874 - val_acc: 0.7770\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 8s 781us/step - loss: 0.4647 - acc: 0.7914 - val_loss: 0.4256 - val_acc: 0.8060\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.4181 - acc: 0.8203 - val_loss: 0.4016 - val_acc: 0.8270\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 8s 786us/step - loss: 0.3898 - acc: 0.8324 - val_loss: 0.3877 - val_acc: 0.8350\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 8s 777us/step - loss: 0.3716 - acc: 0.8431 - val_loss: 0.3838 - val_acc: 0.8370\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 8s 773us/step - loss: 0.3586 - acc: 0.8444 - val_loss: 0.4010 - val_acc: 0.8440\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 9s 892us/step - loss: 0.3511 - acc: 0.8505 - val_loss: 0.3736 - val_acc: 0.8270\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 9s 877us/step - loss: 0.3431 - acc: 0.8482 - val_loss: 0.3689 - val_acc: 0.8350\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 9s 884us/step - loss: 0.3336 - acc: 0.8547 - val_loss: 0.3736 - val_acc: 0.8330\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 9s 881us/step - loss: 0.3300 - acc: 0.8546 - val_loss: 0.4271 - val_acc: 0.8370\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 9s 880us/step - loss: 0.3260 - acc: 0.8571 - val_loss: 0.3961 - val_acc: 0.8460\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 9s 891us/step - loss: 0.3229 - acc: 0.8557 - val_loss: 0.3705 - val_acc: 0.8300\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 9s 890us/step - loss: 0.3212 - acc: 0.8579 - val_loss: 0.3621 - val_acc: 0.8380\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.3132 - acc: 0.8600 - val_loss: 0.3635 - val_acc: 0.8260\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.3073 - acc: 0.8634 - val_loss: 0.3612 - val_acc: 0.8360\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.3088 - acc: 0.8633 - val_loss: 0.3948 - val_acc: 0.8430\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.3067 - acc: 0.8657 - val_loss: 0.3624 - val_acc: 0.8380\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 8s 779us/step - loss: 0.3040 - acc: 0.8614 - val_loss: 0.3619 - val_acc: 0.8370\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.2998 - acc: 0.8656 - val_loss: 0.3693 - val_acc: 0.8350\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 0.2955 - acc: 0.8676 - val_loss: 0.3543 - val_acc: 0.8390\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 0.2976 - acc: 0.8670 - val_loss: 0.3794 - val_acc: 0.8350\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 0.2899 - acc: 0.8688 - val_loss: 0.3670 - val_acc: 0.8350\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 8s 762us/step - loss: 0.2890 - acc: 0.8716 - val_loss: 0.3596 - val_acc: 0.8380\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.2894 - acc: 0.8690 - val_loss: 0.3760 - val_acc: 0.8350\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.2851 - acc: 0.8709 - val_loss: 0.3600 - val_acc: 0.8450\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.2831 - acc: 0.8746 - val_loss: 0.3656 - val_acc: 0.8300\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.2799 - acc: 0.8763 - val_loss: 0.3730 - val_acc: 0.8380\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 8s 755us/step - loss: 0.2773 - acc: 0.8740 - val_loss: 0.3688 - val_acc: 0.8320\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 8s 759us/step - loss: 0.2785 - acc: 0.8759 - val_loss: 0.3761 - val_acc: 0.8310\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.2724 - acc: 0.8780 - val_loss: 0.3669 - val_acc: 0.8450\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 0.2683 - acc: 0.8819 - val_loss: 0.4014 - val_acc: 0.8240\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 7s 748us/step - loss: 0.2697 - acc: 0.8780 - val_loss: 0.3841 - val_acc: 0.8340\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.2647 - acc: 0.8824 - val_loss: 0.3801 - val_acc: 0.8340\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 8s 751us/step - loss: 0.2589 - acc: 0.8828 - val_loss: 0.3815 - val_acc: 0.8370\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 8s 757us/step - loss: 0.2577 - acc: 0.8852 - val_loss: 0.3848 - val_acc: 0.8360\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 8s 791us/step - loss: 0.2565 - acc: 0.8871 - val_loss: 0.3909 - val_acc: 0.8260\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 7s 736us/step - loss: 0.2538 - acc: 0.8870 - val_loss: 0.3942 - val_acc: 0.8330\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 7s 749us/step - loss: 0.2510 - acc: 0.8876 - val_loss: 0.3899 - val_acc: 0.8330\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 7s 743us/step - loss: 0.2488 - acc: 0.8878 - val_loss: 0.4116 - val_acc: 0.8290\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 7s 734us/step - loss: 0.2459 - acc: 0.8930 - val_loss: 0.3956 - val_acc: 0.8310\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 7s 733us/step - loss: 0.2405 - acc: 0.8925 - val_loss: 0.4012 - val_acc: 0.8280\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 7s 740us/step - loss: 0.2380 - acc: 0.8941 - val_loss: 0.4208 - val_acc: 0.8260\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 8s 750us/step - loss: 0.2333 - acc: 0.8962 - val_loss: 0.4213 - val_acc: 0.8250\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 8s 807us/step - loss: 0.2329 - acc: 0.8984 - val_loss: 0.4155 - val_acc: 0.8280\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 8s 811us/step - loss: 0.2279 - acc: 0.8984 - val_loss: 0.4327 - val_acc: 0.8310\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 8s 800us/step - loss: 0.2188 - acc: 0.9053 - val_loss: 0.4571 - val_acc: 0.8310\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 8s 806us/step - loss: 0.2180 - acc: 0.9037 - val_loss: 0.4479 - val_acc: 0.8190\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 8s 796us/step - loss: 0.2132 - acc: 0.9064 - val_loss: 0.4669 - val_acc: 0.8280 0.215 - ETA: 1s - lo\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 8s 796us/step - loss: 0.2092 - acc: 0.9100 - val_loss: 0.4695 - val_acc: 0.8230\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 8s 797us/step - loss: 0.2073 - acc: 0.9121 - val_loss: 0.4580 - val_acc: 0.8160\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 8s 797us/step - loss: 0.2001 - acc: 0.9117 - val_loss: 0.4384 - val_acc: 0.8230\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 8s 789us/step - loss: 0.2006 - acc: 0.9161 - val_loss: 0.4622 - val_acc: 0.8220\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 8s 796us/step - loss: 0.1952 - acc: 0.9172 - val_loss: 0.4667 - val_acc: 0.8190\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 8s 795us/step - loss: 0.1875 - acc: 0.9200 - val_loss: 0.4884 - val_acc: 0.8180\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.1873 - acc: 0.9208 - val_loss: 0.4904 - val_acc: 0.8180\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 8s 770us/step - loss: 0.1805 - acc: 0.9228 - val_loss: 0.5103 - val_acc: 0.8190\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 8s 791us/step - loss: 0.1795 - acc: 0.9246 - val_loss: 0.4937 - val_acc: 0.8170\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 8s 810us/step - loss: 0.1750 - acc: 0.9268 - val_loss: 0.5230 - val_acc: 0.8060\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 8s 778us/step - loss: 0.1731 - acc: 0.9272 - val_loss: 0.5025 - val_acc: 0.8090\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 8s 756us/step - loss: 0.1679 - acc: 0.9313 - val_loss: 0.5251 - val_acc: 0.8020\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 8s 758us/step - loss: 0.1603 - acc: 0.9350 - val_loss: 0.5470 - val_acc: 0.8150\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 0.1579 - acc: 0.9353 - val_loss: 0.5703 - val_acc: 0.8020\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.1521 - acc: 0.9382 - val_loss: 0.5308 - val_acc: 0.8120\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 8s 815us/step - loss: 0.1486 - acc: 0.9410 - val_loss: 0.5785 - val_acc: 0.8060\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 8s 809us/step - loss: 0.1490 - acc: 0.9400 - val_loss: 0.5515 - val_acc: 0.8050\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 8s 780us/step - loss: 0.1438 - acc: 0.9427 - val_loss: 0.5802 - val_acc: 0.8050\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 8s 792us/step - loss: 0.1422 - acc: 0.9435 - val_loss: 0.6063 - val_acc: 0.8110\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 8s 792us/step - loss: 0.1365 - acc: 0.9463 - val_loss: 0.6153 - val_acc: 0.8120\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 8s 786us/step - loss: 0.1302 - acc: 0.9480 - val_loss: 0.5800 - val_acc: 0.8080\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 8s 760us/step - loss: 0.1307 - acc: 0.9495 - val_loss: 0.6265 - val_acc: 0.8020\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 8s 754us/step - loss: 0.1249 - acc: 0.9532 - val_loss: 0.6161 - val_acc: 0.8050\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 8s 785us/step - loss: 0.1241 - acc: 0.9534 - val_loss: 0.6298 - val_acc: 0.8050\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 9s 873us/step - loss: 0.1203 - acc: 0.9542 - val_loss: 0.6553 - val_acc: 0.7880\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 9s 911us/step - loss: 0.1158 - acc: 0.9564 - val_loss: 0.6353 - val_acc: 0.8010\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 9s 945us/step - loss: 0.1122 - acc: 0.9571 - val_loss: 0.6391 - val_acc: 0.8000\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 8s 766us/step - loss: 0.1094 - acc: 0.9585 - val_loss: 0.6653 - val_acc: 0.8080\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 8s 764us/step - loss: 0.1077 - acc: 0.9605 - val_loss: 0.6724 - val_acc: 0.8050\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 7s 744us/step - loss: 0.1051 - acc: 0.9606 - val_loss: 0.6849 - val_acc: 0.8010\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 8s 787us/step - loss: 0.0996 - acc: 0.9621 - val_loss: 0.6779 - val_acc: 0.8050\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 9s 894us/step - loss: 0.1009 - acc: 0.9611 - val_loss: 0.7341 - val_acc: 0.8090\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 8s 750us/step - loss: 0.0972 - acc: 0.9653 - val_loss: 0.7335 - val_acc: 0.8080\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 8s 752us/step - loss: 0.0969 - acc: 0.9651 - val_loss: 0.7105 - val_acc: 0.8010\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 7s 745us/step - loss: 0.0936 - acc: 0.9656 - val_loss: 0.7171 - val_acc: 0.7890\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 8s 775us/step - loss: 0.0903 - acc: 0.9679 - val_loss: 0.7353 - val_acc: 0.8010\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 8s 768us/step - loss: 0.0914 - acc: 0.9667 - val_loss: 0.7681 - val_acc: 0.7880\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 8s 769us/step - loss: 0.0877 - acc: 0.9681 - val_loss: 0.7639 - val_acc: 0.8110\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 8s 776us/step - loss: 0.0859 - acc: 0.9688 - val_loss: 0.7528 - val_acc: 0.8070\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 8s 777us/step - loss: 0.0799 - acc: 0.9710 - val_loss: 0.7778 - val_acc: 0.8100\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 8s 774us/step - loss: 0.0826 - acc: 0.9704 - val_loss: 0.7715 - val_acc: 0.8040\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=100, validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "#Summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999976"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOW WE'LL TEST THE MODEL WITH OUR VERY OWN STORY\n",
    "#NOTE: As the model has been trained on the vocab of just 38 words, we'll have to create the story with the words in vocab\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"Mary journeyed to the kitchen . Mary picked apple . Daniel journeyed to the bedroom .\"\n",
    "my_ques = \"Is Daniel in the bedroom ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(), my_ques.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Mary',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Mary',\n",
       "   'picked',\n",
       "   'apple',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'journeyed',\n",
       "   'to',\n",
       "   'the',\n",
       "   'bedroom',\n",
       "   '.'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'bedroom', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(([my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  2.3639561e-06\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_ans[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
