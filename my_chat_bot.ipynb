{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "my_chat_bot.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMdlM1HE-2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3BswgzeE-2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('single_train_set', 'rb') as f:\n",
        "    train_data = pickle.load(f)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmBiiMC3E-2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('single_test_set', 'rb') as f:\n",
        "    test_data = pickle.load(f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnsVCJlvE-2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5228002-3247-4986-e58e-5d0e3fb9e4eb"
      },
      "source": [
        "test_data[0 : 5]"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['John',\n",
              "   'travelled',\n",
              "   'to',\n",
              "   'the',\n",
              "   'hallway',\n",
              "   '.',\n",
              "   'Mary',\n",
              "   'journeyed',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bathroom',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'John', '?'],\n",
              "  'hallway'),\n",
              " (['Daniel',\n",
              "   'went',\n",
              "   'back',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bathroom',\n",
              "   '.',\n",
              "   'John',\n",
              "   'moved',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bedroom',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'Mary', '?'],\n",
              "  'bathroom'),\n",
              " (['John',\n",
              "   'went',\n",
              "   'to',\n",
              "   'the',\n",
              "   'hallway',\n",
              "   '.',\n",
              "   'Sandra',\n",
              "   'journeyed',\n",
              "   'to',\n",
              "   'the',\n",
              "   'kitchen',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'Sandra', '?'],\n",
              "  'kitchen'),\n",
              " (['Sandra',\n",
              "   'travelled',\n",
              "   'to',\n",
              "   'the',\n",
              "   'hallway',\n",
              "   '.',\n",
              "   'John',\n",
              "   'went',\n",
              "   'to',\n",
              "   'the',\n",
              "   'garden',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'Sandra', '?'],\n",
              "  'hallway'),\n",
              " (['Sandra',\n",
              "   'went',\n",
              "   'back',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bathroom',\n",
              "   '.',\n",
              "   'Sandra',\n",
              "   'moved',\n",
              "   'to',\n",
              "   'the',\n",
              "   'kitchen',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'Sandra', '?'],\n",
              "  'kitchen')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsY2yrOfE-2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "283ed2cb-fa81-4d83-91aa-1c3904db1fda"
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIHTNO65E-2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc389cb8-9399-454d-d317-11526f4a7d69"
      },
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Mary moved to the bathroom . John went to the hallway .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Y9ZoVHE-2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6c88930-abd6-4b26-a96d-2792b06b2357"
      },
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Where is Mary ?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onZ67tiJE-2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ef0489e-3338-469c-8308-63aee4c1bebd"
      },
      "source": [
        "train_data[0][2]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'bathroom'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfSbyLFvE-2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data = test_data + train_data"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYGQ_oUYE-2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e6704ce-fa15-4d54-e141-c2e69eadaf22"
      },
      "source": [
        "len(all_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqGDj3vcE-2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61e8fd2d-4d47-4806-d013-98ad2c285a8d"
      },
      "source": [
        "vocab = set()\n",
        "count = 0\n",
        "for story, question, answer in train_data:\n",
        "    if ' ' in story or ' ' in question  or ' ' in answer:\n",
        "        print(story, question, answer)\n",
        "        count += 1\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "#     vocab = vocab.union(set([answer]))\n",
        "len(vocab)\n",
        "print(count)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eJG_unRfE-2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "93dfe5a4-c009-4085-819b-3717c5ff8fb2"
      },
      "source": [
        "# vocab = vocab.union(set(['yes', 'no']))\n",
        "vocab"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'Where',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'garden',\n",
              " 'hallway',\n",
              " 'is',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'moved',\n",
              " 'office',\n",
              " 'the',\n",
              " 'to',\n",
              " 'travelled',\n",
              " 'went'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHSsxaKsE-2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len = len(vocab) + 1  #one extra for keras pad-sequences placeholder"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E3XqewME-2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d290cbd5-1d55-46d0-8b5a-c1ba73a25801"
      },
      "source": [
        "vocab_len"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ_63wZNE-2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LONGEST STORY\n",
        "all_story_lengths = [len(data[0]) for data in all_data]\n",
        "\n",
        "# LONGEST QUESTION\n",
        "all_ques_lengths = [len(data[1]) for data in all_data]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SkKCqMHE-2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_story_len = max(all_story_lengths)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2XTZp0fE-2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4974f0a7-1edb-4b94-d9a4-fff092ee429c"
      },
      "source": [
        "max_story_len"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lsh1Kv7E-2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_ques_len = max(all_ques_lengths)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRES_wOME-2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e242f4-9714-4c17-96e7-90e47e4d5945"
      },
      "source": [
        "max_ques_len"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcOiz9OpE-2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "342611ab-72e6-4018-e849-fb10b7d08692"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUEtnqlIE-2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(filters=[])  # default fiter is not required"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG_1aVznE-2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM2_UzfDE-2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3c72b9f-24e1-468c-9fc4-a719b860fa2c"
      },
      "source": [
        "tokenizer.texts_to_sequences(all_data[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 18, 14, 13, 21, 15, 8, 19, 14, 13, 1, 15], [16, 12, 3, 10], [21]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6v3F7IyE-2y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4e02c8c5-2898-4ecb-d85c-3730ea53fb6b"
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.': 15,\n",
              " '?': 10,\n",
              " 'back': 2,\n",
              " 'bathroom': 1,\n",
              " 'bedroom': 5,\n",
              " 'daniel': 20,\n",
              " 'garden': 11,\n",
              " 'hallway': 21,\n",
              " 'is': 12,\n",
              " 'john': 3,\n",
              " 'journeyed': 19,\n",
              " 'kitchen': 6,\n",
              " 'mary': 8,\n",
              " 'moved': 9,\n",
              " 'office': 7,\n",
              " 'sandra': 4,\n",
              " 'the': 13,\n",
              " 'to': 14,\n",
              " 'travelled': 18,\n",
              " 'went': 17,\n",
              " 'where': 16}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TzWF5wAE-20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_ques_len=max_ques_len):\n",
        "    X = []\n",
        "    Xq = []\n",
        "    Y = []\n",
        "    \n",
        "    for story, question, answer in data:\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        xq = [word_index[word.lower()] for word in question]\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        \n",
        "        y[word_index[answer]] = 1\n",
        "        \n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "        \n",
        "    return (pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_ques_len), np.array(Y))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOBD7IpjE-22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d871Tf1WE-24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRfRRCrKE-26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4fe540fe-e3b7-44aa-b564-356ccb887b1b"
      },
      "source": [
        "inputs_train"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  8, ..., 13, 21, 15],\n",
              "       [ 0, 20, 17, ..., 13, 11, 15],\n",
              "       [ 0,  0,  3, ..., 13,  1, 15],\n",
              "       ...,\n",
              "       [ 4, 17,  2, ..., 13,  6, 15],\n",
              "       [ 0, 20, 17, ..., 13,  1, 15],\n",
              "       [ 0,  3, 17, ..., 13,  5, 15]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VplrV7V3E-27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fdf0fa83-aedd-475f-c720-b06a83799f2b"
      },
      "source": [
        "sum(answers_test), len(answers_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0., 149.,   0.,   0.,   0., 171., 157., 182.,   0.,   0.,   0.,\n",
              "        187.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 154.]),\n",
              " 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTAI687vE-29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Dense, LSTM, Input, Activation, Permute, Dropout, add, dot, concatenate"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDovcEmtE-2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PLCEHOLDER shape=(max_story_len, batch_size)\n",
        "input_sequence = Input((max_story_len, ))\n",
        "question = Input((max_ques_len, ))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgVvHlMmE-3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAME AS vocab_len\n",
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcm32ryjE-3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2e773ea-e9c3-4bf0-ee45-6f10f51ce6b0"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyk6oLn7E-3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INPUT ENCODER M\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT\n",
        "# (samples, max_len_story, embedding_dim)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGr4frO9E-3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INPUT ENCODER C\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_ques_len))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT\n",
        "# (samples, max_len_story, max_ques_len)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FujW9cNHE-3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# QUESTION ENCODER\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "\n",
        "# OUTPUT\n",
        "# (samples, max_len_story, embedding_dim)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54-9tNFRE-3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENCODED <--- ENCODER(INPUT)\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL_MpJ8nE-3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "36595ce3-8900-4783-84d4-fd9cd18b053a"
      },
      "source": [
        "input_encoded_m, question_encoded, input_encoded_c"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor 'sequential_1/dropout_2/cond/Identity:0' shape=(None, 14, 64) dtype=float32>,\n",
              " <tf.Tensor 'sequential_3/dropout_3/cond/Identity:0' shape=(None, 4, 64) dtype=float32>,\n",
              " <tf.Tensor 'sequential_2/embedding_2/embedding_lookup/Identity_1:0' shape=(None, 14, 4) dtype=float32>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdIEk16NE-3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculating match between m (Embedding A) and q (Embedding B)\n",
        "\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2,2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvzseEmSE-3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65f8af15-bc75-47b0-d6f8-5343d2006bf6"
      },
      "source": [
        "match"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'activation_1/truediv:0' shape=(None, 14, 4) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waAVQnDXE-3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "response = add([input_encoded_c, match])\n",
        "response = Permute((2, 1))(response)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drzF131yE-3Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3826a8c0-d7e6-4eac-d3ca-6016e846567e"
      },
      "source": [
        "response"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'permute_1/transpose:0' shape=(None, 4, 14) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My9mDqhjE-3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AODd-yalE-3V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc5947af-c8f6-470f-b5b0-3f116fd59dc4"
      },
      "source": [
        "answer"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 4, 78) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOipqGJ4E-3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = LSTM(32)(answer)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUv6GWw3E-3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = Dropout(0.5)(answer)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tma-CipE-3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = Dense(vocab_size)(answer) # (samples, vocab_size) YES/NO"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR9PGHQVE-3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb4d0ae0-f205-4bda-fc86-743483e56344"
      },
      "source": [
        "answer"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_1/BiasAdd:0' shape=(None, 22) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvKAE2ZcE-3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPhugM8ME-3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([input_sequence, question], answer)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCqkETeAE-3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XV35wFVJE-3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "57133de5-74a4-4a32-d390-e3c87caaf8ec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 14)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       multiple             1408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       multiple             1408        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 14, 4)        0           sequential_1[1][0]               \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       multiple             88          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 14, 4)        0           dot_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 14, 4)        0           sequential_2[1][0]               \n",
            "                                                                 activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 4, 14)        0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4, 78)        0           permute_1[0][0]                  \n",
            "                                                                 sequential_3[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 32)           14208       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           726         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 22)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 17,838\n",
            "Trainable params: 17,838\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAebOBNNE-3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a5d89e5-d36f-4acc-e397-5bf2bc9b20de"
      },
      "source": [
        "history = model.fit([inputs_train, queries_train], answers_train, batch_size=32, epochs=150, validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/150\n",
            "10000/10000 [==============================] - 2s 207us/step - loss: 2.0019 - accuracy: 0.1776 - val_loss: 1.7697 - val_accuracy: 0.2520\n",
            "Epoch 2/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.7269 - accuracy: 0.2309 - val_loss: 1.6643 - val_accuracy: 0.2540\n",
            "Epoch 3/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.6533 - accuracy: 0.2933 - val_loss: 1.6027 - val_accuracy: 0.3560\n",
            "Epoch 4/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 1.5603 - accuracy: 0.3853 - val_loss: 1.5106 - val_accuracy: 0.3990\n",
            "Epoch 5/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.5225 - accuracy: 0.4069 - val_loss: 1.4946 - val_accuracy: 0.4000\n",
            "Epoch 6/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 1.5081 - accuracy: 0.4114 - val_loss: 1.5095 - val_accuracy: 0.4160\n",
            "Epoch 7/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.4954 - accuracy: 0.4302 - val_loss: 1.4878 - val_accuracy: 0.4270\n",
            "Epoch 8/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.4878 - accuracy: 0.4317 - val_loss: 1.4735 - val_accuracy: 0.4260\n",
            "Epoch 9/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 1.4724 - accuracy: 0.4472 - val_loss: 1.4632 - val_accuracy: 0.4560\n",
            "Epoch 10/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.4518 - accuracy: 0.4722 - val_loss: 1.4425 - val_accuracy: 0.4620\n",
            "Epoch 11/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.4294 - accuracy: 0.4977 - val_loss: 1.3998 - val_accuracy: 0.5280\n",
            "Epoch 12/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 1.4120 - accuracy: 0.5144 - val_loss: 1.3735 - val_accuracy: 0.5270\n",
            "Epoch 13/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 1.3921 - accuracy: 0.5197 - val_loss: 1.3574 - val_accuracy: 0.5270\n",
            "Epoch 14/150\n",
            "10000/10000 [==============================] - 1s 142us/step - loss: 1.3838 - accuracy: 0.5125 - val_loss: 1.3454 - val_accuracy: 0.5280\n",
            "Epoch 15/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.3668 - accuracy: 0.5162 - val_loss: 1.3319 - val_accuracy: 0.5160\n",
            "Epoch 16/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.3447 - accuracy: 0.5236 - val_loss: 1.3225 - val_accuracy: 0.5270\n",
            "Epoch 17/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.3505 - accuracy: 0.5179 - val_loss: 1.3196 - val_accuracy: 0.5090\n",
            "Epoch 18/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.3326 - accuracy: 0.5204 - val_loss: 1.3112 - val_accuracy: 0.5150\n",
            "Epoch 19/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.3232 - accuracy: 0.5206 - val_loss: 1.3068 - val_accuracy: 0.5260\n",
            "Epoch 20/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 1.3294 - accuracy: 0.5135 - val_loss: 1.2951 - val_accuracy: 0.5250\n",
            "Epoch 21/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.3227 - accuracy: 0.5177 - val_loss: 1.2909 - val_accuracy: 0.5120\n",
            "Epoch 22/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.3092 - accuracy: 0.5155 - val_loss: 1.2822 - val_accuracy: 0.5270\n",
            "Epoch 23/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.3044 - accuracy: 0.5203 - val_loss: 1.2855 - val_accuracy: 0.5070\n",
            "Epoch 24/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.2963 - accuracy: 0.5217 - val_loss: 1.2824 - val_accuracy: 0.5160\n",
            "Epoch 25/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 1.2952 - accuracy: 0.5161 - val_loss: 1.2965 - val_accuracy: 0.5040\n",
            "Epoch 26/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.2955 - accuracy: 0.5209 - val_loss: 1.2784 - val_accuracy: 0.5180\n",
            "Epoch 27/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.2812 - accuracy: 0.5199 - val_loss: 1.2612 - val_accuracy: 0.5290\n",
            "Epoch 28/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 1.2757 - accuracy: 0.5300 - val_loss: 1.2505 - val_accuracy: 0.5450\n",
            "Epoch 29/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 1.2421 - accuracy: 0.5562 - val_loss: 1.2044 - val_accuracy: 0.5800\n",
            "Epoch 30/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 1.1858 - accuracy: 0.5924 - val_loss: 1.1156 - val_accuracy: 0.6240\n",
            "Epoch 31/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 1.0923 - accuracy: 0.6475 - val_loss: 0.9732 - val_accuracy: 0.6880\n",
            "Epoch 32/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.9843 - accuracy: 0.6986 - val_loss: 0.8752 - val_accuracy: 0.7270\n",
            "Epoch 33/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.8883 - accuracy: 0.7336 - val_loss: 0.8111 - val_accuracy: 0.7540\n",
            "Epoch 34/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.8234 - accuracy: 0.7487 - val_loss: 0.7531 - val_accuracy: 0.7550\n",
            "Epoch 35/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.7630 - accuracy: 0.7621 - val_loss: 0.6811 - val_accuracy: 0.7550\n",
            "Epoch 36/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.6897 - accuracy: 0.7634 - val_loss: 0.6173 - val_accuracy: 0.7590\n",
            "Epoch 37/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.6222 - accuracy: 0.7722 - val_loss: 0.5731 - val_accuracy: 0.7560\n",
            "Epoch 38/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.5734 - accuracy: 0.7730 - val_loss: 0.5468 - val_accuracy: 0.7530\n",
            "Epoch 39/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.5420 - accuracy: 0.7794 - val_loss: 0.5360 - val_accuracy: 0.7620\n",
            "Epoch 40/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.5191 - accuracy: 0.7783 - val_loss: 0.5318 - val_accuracy: 0.7540\n",
            "Epoch 41/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.5096 - accuracy: 0.7799 - val_loss: 0.5299 - val_accuracy: 0.7530\n",
            "Epoch 42/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.5087 - accuracy: 0.7782 - val_loss: 0.5279 - val_accuracy: 0.7500\n",
            "Epoch 43/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4950 - accuracy: 0.7803 - val_loss: 0.5278 - val_accuracy: 0.7440\n",
            "Epoch 44/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4974 - accuracy: 0.7831 - val_loss: 0.5256 - val_accuracy: 0.7530\n",
            "Epoch 45/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4927 - accuracy: 0.7833 - val_loss: 0.5247 - val_accuracy: 0.7450\n",
            "Epoch 46/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4844 - accuracy: 0.7895 - val_loss: 0.5249 - val_accuracy: 0.7490\n",
            "Epoch 47/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4796 - accuracy: 0.7880 - val_loss: 0.5250 - val_accuracy: 0.7490\n",
            "Epoch 48/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4851 - accuracy: 0.7864 - val_loss: 0.5259 - val_accuracy: 0.7480\n",
            "Epoch 49/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4811 - accuracy: 0.7902 - val_loss: 0.5241 - val_accuracy: 0.7460\n",
            "Epoch 50/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4803 - accuracy: 0.7865 - val_loss: 0.5241 - val_accuracy: 0.7460\n",
            "Epoch 51/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4805 - accuracy: 0.7861 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
            "Epoch 52/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4802 - accuracy: 0.7839 - val_loss: 0.5235 - val_accuracy: 0.7530\n",
            "Epoch 53/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.4863 - accuracy: 0.7881 - val_loss: 0.5247 - val_accuracy: 0.7390\n",
            "Epoch 54/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4788 - accuracy: 0.7874 - val_loss: 0.5244 - val_accuracy: 0.7420\n",
            "Epoch 55/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4825 - accuracy: 0.7908 - val_loss: 0.5235 - val_accuracy: 0.7510\n",
            "Epoch 56/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4766 - accuracy: 0.7913 - val_loss: 0.5228 - val_accuracy: 0.7530\n",
            "Epoch 57/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4792 - accuracy: 0.7900 - val_loss: 0.5230 - val_accuracy: 0.7560\n",
            "Epoch 58/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4782 - accuracy: 0.7875 - val_loss: 0.5236 - val_accuracy: 0.7540\n",
            "Epoch 59/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4779 - accuracy: 0.7884 - val_loss: 0.5245 - val_accuracy: 0.7490\n",
            "Epoch 60/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4809 - accuracy: 0.7875 - val_loss: 0.5242 - val_accuracy: 0.7460\n",
            "Epoch 61/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.4810 - accuracy: 0.7849 - val_loss: 0.5233 - val_accuracy: 0.7510\n",
            "Epoch 62/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4761 - accuracy: 0.7927 - val_loss: 0.5272 - val_accuracy: 0.7560\n",
            "Epoch 63/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4795 - accuracy: 0.7912 - val_loss: 0.5245 - val_accuracy: 0.7510\n",
            "Epoch 64/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4748 - accuracy: 0.7939 - val_loss: 0.5249 - val_accuracy: 0.7500\n",
            "Epoch 65/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4760 - accuracy: 0.7914 - val_loss: 0.5230 - val_accuracy: 0.7550\n",
            "Epoch 66/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4746 - accuracy: 0.7902 - val_loss: 0.5220 - val_accuracy: 0.7570\n",
            "Epoch 67/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4806 - accuracy: 0.7904 - val_loss: 0.5242 - val_accuracy: 0.7550\n",
            "Epoch 68/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4756 - accuracy: 0.7926 - val_loss: 0.5247 - val_accuracy: 0.7470\n",
            "Epoch 69/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4691 - accuracy: 0.7924 - val_loss: 0.5232 - val_accuracy: 0.7590\n",
            "Epoch 70/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4748 - accuracy: 0.7924 - val_loss: 0.5237 - val_accuracy: 0.7530\n",
            "Epoch 71/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4673 - accuracy: 0.7940 - val_loss: 0.5244 - val_accuracy: 0.7530\n",
            "Epoch 72/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4721 - accuracy: 0.7941 - val_loss: 0.5250 - val_accuracy: 0.7510\n",
            "Epoch 73/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4762 - accuracy: 0.7920 - val_loss: 0.5255 - val_accuracy: 0.7500\n",
            "Epoch 74/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4706 - accuracy: 0.7946 - val_loss: 0.5271 - val_accuracy: 0.7580\n",
            "Epoch 75/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4815 - accuracy: 0.7917 - val_loss: 0.5241 - val_accuracy: 0.7540\n",
            "Epoch 76/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4724 - accuracy: 0.7950 - val_loss: 0.5245 - val_accuracy: 0.7520\n",
            "Epoch 77/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4721 - accuracy: 0.7914 - val_loss: 0.5259 - val_accuracy: 0.7570\n",
            "Epoch 78/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4719 - accuracy: 0.7947 - val_loss: 0.5253 - val_accuracy: 0.7570\n",
            "Epoch 79/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4774 - accuracy: 0.7938 - val_loss: 0.5263 - val_accuracy: 0.7520\n",
            "Epoch 80/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4733 - accuracy: 0.7916 - val_loss: 0.5258 - val_accuracy: 0.7580\n",
            "Epoch 81/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4677 - accuracy: 0.7975 - val_loss: 0.5263 - val_accuracy: 0.7550\n",
            "Epoch 82/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4746 - accuracy: 0.7966 - val_loss: 0.5269 - val_accuracy: 0.7560\n",
            "Epoch 83/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4716 - accuracy: 0.7929 - val_loss: 0.5286 - val_accuracy: 0.7500\n",
            "Epoch 84/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4703 - accuracy: 0.7960 - val_loss: 0.5276 - val_accuracy: 0.7540\n",
            "Epoch 85/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4712 - accuracy: 0.7974 - val_loss: 0.5288 - val_accuracy: 0.7570\n",
            "Epoch 86/150\n",
            "10000/10000 [==============================] - 1s 133us/step - loss: 0.4740 - accuracy: 0.7968 - val_loss: 0.5252 - val_accuracy: 0.7600\n",
            "Epoch 87/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4736 - accuracy: 0.7950 - val_loss: 0.5257 - val_accuracy: 0.7540\n",
            "Epoch 88/150\n",
            "10000/10000 [==============================] - 1s 133us/step - loss: 0.4685 - accuracy: 0.7973 - val_loss: 0.5299 - val_accuracy: 0.7520\n",
            "Epoch 89/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4756 - accuracy: 0.7957 - val_loss: 0.5260 - val_accuracy: 0.7540\n",
            "Epoch 90/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4693 - accuracy: 0.7983 - val_loss: 0.5254 - val_accuracy: 0.7530\n",
            "Epoch 91/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4736 - accuracy: 0.7987 - val_loss: 0.5263 - val_accuracy: 0.7550\n",
            "Epoch 92/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4714 - accuracy: 0.7991 - val_loss: 0.5316 - val_accuracy: 0.7510\n",
            "Epoch 93/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4727 - accuracy: 0.7979 - val_loss: 0.5275 - val_accuracy: 0.7560\n",
            "Epoch 94/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4683 - accuracy: 0.7973 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
            "Epoch 95/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4694 - accuracy: 0.7938 - val_loss: 0.5283 - val_accuracy: 0.7530\n",
            "Epoch 96/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4754 - accuracy: 0.8018 - val_loss: 0.5283 - val_accuracy: 0.7510\n",
            "Epoch 97/150\n",
            "10000/10000 [==============================] - 1s 142us/step - loss: 0.4715 - accuracy: 0.8008 - val_loss: 0.5297 - val_accuracy: 0.7540\n",
            "Epoch 98/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4663 - accuracy: 0.7987 - val_loss: 0.5272 - val_accuracy: 0.7560\n",
            "Epoch 99/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4690 - accuracy: 0.7995 - val_loss: 0.5298 - val_accuracy: 0.7570\n",
            "Epoch 100/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.4726 - accuracy: 0.8003 - val_loss: 0.5328 - val_accuracy: 0.7570\n",
            "Epoch 101/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4665 - accuracy: 0.7990 - val_loss: 0.5279 - val_accuracy: 0.7570\n",
            "Epoch 102/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4693 - accuracy: 0.7958 - val_loss: 0.5288 - val_accuracy: 0.7570\n",
            "Epoch 103/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4690 - accuracy: 0.7967 - val_loss: 0.5296 - val_accuracy: 0.7540\n",
            "Epoch 104/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4652 - accuracy: 0.8012 - val_loss: 0.5311 - val_accuracy: 0.7580\n",
            "Epoch 105/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4616 - accuracy: 0.8035 - val_loss: 0.5365 - val_accuracy: 0.7550\n",
            "Epoch 106/150\n",
            "10000/10000 [==============================] - 1s 134us/step - loss: 0.4647 - accuracy: 0.7996 - val_loss: 0.5317 - val_accuracy: 0.7600\n",
            "Epoch 107/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4661 - accuracy: 0.7990 - val_loss: 0.5289 - val_accuracy: 0.7560\n",
            "Epoch 108/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4672 - accuracy: 0.8034 - val_loss: 0.5354 - val_accuracy: 0.7590\n",
            "Epoch 109/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4655 - accuracy: 0.8008 - val_loss: 0.5294 - val_accuracy: 0.7560\n",
            "Epoch 110/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4683 - accuracy: 0.8007 - val_loss: 0.5282 - val_accuracy: 0.7600\n",
            "Epoch 111/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4655 - accuracy: 0.8035 - val_loss: 0.5298 - val_accuracy: 0.7570\n",
            "Epoch 112/150\n",
            "10000/10000 [==============================] - 1s 133us/step - loss: 0.4625 - accuracy: 0.8024 - val_loss: 0.5307 - val_accuracy: 0.7590\n",
            "Epoch 113/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4640 - accuracy: 0.7992 - val_loss: 0.5375 - val_accuracy: 0.7560\n",
            "Epoch 114/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4720 - accuracy: 0.8026 - val_loss: 0.5328 - val_accuracy: 0.7540\n",
            "Epoch 115/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4669 - accuracy: 0.8025 - val_loss: 0.5296 - val_accuracy: 0.7560\n",
            "Epoch 116/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4679 - accuracy: 0.8035 - val_loss: 0.5300 - val_accuracy: 0.7490\n",
            "Epoch 117/150\n",
            "10000/10000 [==============================] - 1s 135us/step - loss: 0.4637 - accuracy: 0.8029 - val_loss: 0.5349 - val_accuracy: 0.7550\n",
            "Epoch 118/150\n",
            "10000/10000 [==============================] - 1s 136us/step - loss: 0.4689 - accuracy: 0.8008 - val_loss: 0.5329 - val_accuracy: 0.7530\n",
            "Epoch 119/150\n",
            "10000/10000 [==============================] - 1s 141us/step - loss: 0.4645 - accuracy: 0.8064 - val_loss: 0.5371 - val_accuracy: 0.7490\n",
            "Epoch 120/150\n",
            "10000/10000 [==============================] - 1s 141us/step - loss: 0.4628 - accuracy: 0.8037 - val_loss: 0.5345 - val_accuracy: 0.7570\n",
            "Epoch 121/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4620 - accuracy: 0.8034 - val_loss: 0.5345 - val_accuracy: 0.7580\n",
            "Epoch 122/150\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.4680 - accuracy: 0.8049 - val_loss: 0.5368 - val_accuracy: 0.7570\n",
            "Epoch 123/150\n",
            "10000/10000 [==============================] - 1s 147us/step - loss: 0.4628 - accuracy: 0.8039 - val_loss: 0.5363 - val_accuracy: 0.7520\n",
            "Epoch 124/150\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.4624 - accuracy: 0.8039 - val_loss: 0.5396 - val_accuracy: 0.7620\n",
            "Epoch 125/150\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.4576 - accuracy: 0.8087 - val_loss: 0.5373 - val_accuracy: 0.7500\n",
            "Epoch 126/150\n",
            "10000/10000 [==============================] - 1s 141us/step - loss: 0.4576 - accuracy: 0.8058 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
            "Epoch 127/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4619 - accuracy: 0.8062 - val_loss: 0.5367 - val_accuracy: 0.7510\n",
            "Epoch 128/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.4628 - accuracy: 0.8009 - val_loss: 0.5323 - val_accuracy: 0.7470\n",
            "Epoch 129/150\n",
            "10000/10000 [==============================] - 1s 139us/step - loss: 0.4676 - accuracy: 0.8039 - val_loss: 0.5372 - val_accuracy: 0.7530\n",
            "Epoch 130/150\n",
            "10000/10000 [==============================] - 1s 141us/step - loss: 0.4646 - accuracy: 0.8063 - val_loss: 0.5369 - val_accuracy: 0.7540\n",
            "Epoch 131/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4611 - accuracy: 0.8067 - val_loss: 0.5357 - val_accuracy: 0.7550\n",
            "Epoch 132/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4628 - accuracy: 0.8056 - val_loss: 0.5344 - val_accuracy: 0.7550\n",
            "Epoch 133/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4528 - accuracy: 0.8050 - val_loss: 0.5416 - val_accuracy: 0.7510\n",
            "Epoch 134/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4542 - accuracy: 0.8083 - val_loss: 0.5372 - val_accuracy: 0.7520\n",
            "Epoch 135/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4559 - accuracy: 0.8055 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 136/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4641 - accuracy: 0.8060 - val_loss: 0.5390 - val_accuracy: 0.7520\n",
            "Epoch 137/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4608 - accuracy: 0.8050 - val_loss: 0.5402 - val_accuracy: 0.7570\n",
            "Epoch 138/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4578 - accuracy: 0.8038 - val_loss: 0.5575 - val_accuracy: 0.7470\n",
            "Epoch 139/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4615 - accuracy: 0.8056 - val_loss: 0.5398 - val_accuracy: 0.7470\n",
            "Epoch 140/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4577 - accuracy: 0.8027 - val_loss: 0.5404 - val_accuracy: 0.7580\n",
            "Epoch 141/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4583 - accuracy: 0.8070 - val_loss: 0.5417 - val_accuracy: 0.7510\n",
            "Epoch 142/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4589 - accuracy: 0.8095 - val_loss: 0.5490 - val_accuracy: 0.7530\n",
            "Epoch 143/150\n",
            "10000/10000 [==============================] - 1s 137us/step - loss: 0.4585 - accuracy: 0.8061 - val_loss: 0.5422 - val_accuracy: 0.7500\n",
            "Epoch 144/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4546 - accuracy: 0.8088 - val_loss: 0.5443 - val_accuracy: 0.7510\n",
            "Epoch 145/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4567 - accuracy: 0.8067 - val_loss: 0.5374 - val_accuracy: 0.7550\n",
            "Epoch 146/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4559 - accuracy: 0.8075 - val_loss: 0.5521 - val_accuracy: 0.7480\n",
            "Epoch 147/150\n",
            "10000/10000 [==============================] - 1s 140us/step - loss: 0.4559 - accuracy: 0.8077 - val_loss: 0.5444 - val_accuracy: 0.7490\n",
            "Epoch 148/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4562 - accuracy: 0.8099 - val_loss: 0.5384 - val_accuracy: 0.7570\n",
            "Epoch 149/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4544 - accuracy: 0.8077 - val_loss: 0.5418 - val_accuracy: 0.7520\n",
            "Epoch 150/150\n",
            "10000/10000 [==============================] - 1s 138us/step - loss: 0.4568 - accuracy: 0.8104 - val_loss: 0.5502 - val_accuracy: 0.7540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6NsRYQpE-3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('my_new_single_trained_model_1.h5')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXd73asvE-3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "5bb0cf51-31d9-4832-dc2e-4476ea2b0865"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(history.history.keys())\n",
        "#Summarize history for accuracy\n",
        "print(history.history)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n",
            "{'val_loss': [1.7696758060455322, 1.6643094215393066, 1.6026945781707764, 1.5105930709838866, 1.4945538997650147, 1.5094666805267334, 1.4877574920654297, 1.4735319538116456, 1.4631745767593385, 1.4424916648864745, 1.3998296527862548, 1.3734779539108277, 1.3574451189041137, 1.345405014038086, 1.3319494457244874, 1.3225426998138428, 1.3196471815109252, 1.3111588115692139, 1.30682315826416, 1.2950904531478882, 1.2909039707183838, 1.2821711339950561, 1.2855118217468262, 1.2824398803710937, 1.2964886026382447, 1.2783723087310792, 1.2611988992691041, 1.2505497131347656, 1.204425012588501, 1.1155901050567627, 0.9732022647857665, 0.875159215927124, 0.811066722869873, 0.7531215629577637, 0.6811474895477295, 0.6172580318450928, 0.5731070671081543, 0.5467709472179413, 0.5359936792850495, 0.5317655823230744, 0.5298782169818879, 0.527853120803833, 0.5278377587795258, 0.5255903117656707, 0.5247368679046631, 0.5249459700584411, 0.5249957730770111, 0.5259308745861053, 0.5240595338344574, 0.5241498014926911, 0.5241193866729736, 0.5235087049007415, 0.5246650288105011, 0.5243889336585998, 0.5234936547279357, 0.5228354029655456, 0.5230226190090179, 0.5235912334918976, 0.5245224149227142, 0.5241512660980224, 0.5232860107421875, 0.5271901230812073, 0.52454279088974, 0.5248829917907715, 0.5229784002304078, 0.5219882390499115, 0.5241821372509002, 0.5246967749595642, 0.5231926367282868, 0.5237234301567077, 0.5243618612289429, 0.5249906215667725, 0.525510600566864, 0.5270975692272186, 0.5241455314159393, 0.5244560449123382, 0.5259426140785217, 0.5252759337425232, 0.5263482196331024, 0.52583171916008, 0.5262905242443084, 0.5269383935928345, 0.5286136882305146, 0.5275864164829254, 0.528775705575943, 0.5251729815006256, 0.5256941523551941, 0.5299460101127624, 0.525987874031067, 0.525421448469162, 0.5262867374420166, 0.5315679998397828, 0.5275198662281037, 0.5299638283252716, 0.5282734301090241, 0.5282795557975769, 0.5296900942325592, 0.5271879467964172, 0.5297970197200775, 0.5328050272464753, 0.5278932945728302, 0.5287749576568603, 0.5296332414150238, 0.5311312847137452, 0.5365238633155823, 0.5316509861946106, 0.5289300086498261, 0.5354235591888428, 0.5293668472766876, 0.5281840579509736, 0.5297975227832794, 0.5307489025592804, 0.5374674551486969, 0.532817920923233, 0.5295936214923859, 0.5300031645298005, 0.5349474301338196, 0.532894127368927, 0.5370885210037232, 0.5344547731876373, 0.5344701871871949, 0.5367582347393036, 0.5363235664367676, 0.5395735273361206, 0.5372795255184174, 0.5364667043685913, 0.5367044653892518, 0.5322850615978241, 0.5372176008224487, 0.5368769688606262, 0.5356818342208862, 0.5343557155132294, 0.5415811495780944, 0.5372278261184692, 0.5383108110427857, 0.5390474309921265, 0.5401932864189148, 0.5574579510688782, 0.5398215498924256, 0.5403720717430115, 0.5416838688850403, 0.5490177297592163, 0.5421539001464843, 0.5443264780044555, 0.5374044289588928, 0.5520539832115173, 0.544448748588562, 0.5383951807022095, 0.5418184633255005, 0.550182370185852], 'val_accuracy': [0.25200000405311584, 0.2540000081062317, 0.35600000619888306, 0.39899998903274536, 0.4000000059604645, 0.41600000858306885, 0.4269999861717224, 0.4259999990463257, 0.4560000002384186, 0.4620000123977661, 0.527999997138977, 0.5270000100135803, 0.5270000100135803, 0.527999997138977, 0.515999972820282, 0.5270000100135803, 0.5090000033378601, 0.5149999856948853, 0.5260000228881836, 0.5249999761581421, 0.5120000243186951, 0.5270000100135803, 0.5070000290870667, 0.515999972820282, 0.5040000081062317, 0.5180000066757202, 0.5289999842643738, 0.5450000166893005, 0.5799999833106995, 0.6240000128746033, 0.6880000233650208, 0.7269999980926514, 0.7540000081062317, 0.7549999952316284, 0.7549999952316284, 0.7590000033378601, 0.7559999823570251, 0.753000020980835, 0.7620000243186951, 0.7540000081062317, 0.753000020980835, 0.75, 0.7440000176429749, 0.753000020980835, 0.7450000047683716, 0.7490000128746033, 0.7490000128746033, 0.7480000257492065, 0.7459999918937683, 0.7459999918937683, 0.75, 0.753000020980835, 0.7390000224113464, 0.7419999837875366, 0.7509999871253967, 0.753000020980835, 0.7559999823570251, 0.7540000081062317, 0.7490000128746033, 0.7459999918937683, 0.7509999871253967, 0.7559999823570251, 0.7509999871253967, 0.75, 0.7549999952316284, 0.7570000290870667, 0.7549999952316284, 0.746999979019165, 0.7590000033378601, 0.753000020980835, 0.753000020980835, 0.7509999871253967, 0.75, 0.7580000162124634, 0.7540000081062317, 0.7519999742507935, 0.7570000290870667, 0.7570000290870667, 0.7519999742507935, 0.7580000162124634, 0.7549999952316284, 0.7559999823570251, 0.75, 0.7540000081062317, 0.7570000290870667, 0.7599999904632568, 0.7540000081062317, 0.7519999742507935, 0.7540000081062317, 0.753000020980835, 0.7549999952316284, 0.7509999871253967, 0.7559999823570251, 0.75, 0.753000020980835, 0.7509999871253967, 0.7540000081062317, 0.7559999823570251, 0.7570000290870667, 0.7570000290870667, 0.7570000290870667, 0.7570000290870667, 0.7540000081062317, 0.7580000162124634, 0.7549999952316284, 0.7599999904632568, 0.7559999823570251, 0.7590000033378601, 0.7559999823570251, 0.7599999904632568, 0.7570000290870667, 0.7590000033378601, 0.7559999823570251, 0.7540000081062317, 0.7559999823570251, 0.7490000128746033, 0.7549999952316284, 0.753000020980835, 0.7490000128746033, 0.7570000290870667, 0.7580000162124634, 0.7570000290870667, 0.7519999742507935, 0.7620000243186951, 0.75, 0.75, 0.7509999871253967, 0.746999979019165, 0.753000020980835, 0.7540000081062317, 0.7549999952316284, 0.7549999952316284, 0.7509999871253967, 0.7519999742507935, 0.75, 0.7519999742507935, 0.7570000290870667, 0.746999979019165, 0.746999979019165, 0.7580000162124634, 0.7509999871253967, 0.753000020980835, 0.75, 0.7509999871253967, 0.7549999952316284, 0.7480000257492065, 0.7490000128746033, 0.7570000290870667, 0.7519999742507935, 0.7540000081062317], 'loss': [2.0018750547409057, 1.726937532234192, 1.6533054027557372, 1.5603148555755615, 1.5224743476867675, 1.5080766445159912, 1.4953826995849608, 1.4878014770507813, 1.4724382543563843, 1.4517674814224244, 1.429365929031372, 1.4119546689987184, 1.3920798721313477, 1.3838184719085693, 1.3668410255432129, 1.344699618911743, 1.350544267463684, 1.332564442062378, 1.32315439453125, 1.3294333967208862, 1.3227409036636353, 1.3092098936080934, 1.3043621170043946, 1.2962618328094482, 1.295166262435913, 1.295516054725647, 1.2812096969604492, 1.2757369598388673, 1.2421309633255004, 1.1857943098068238, 1.0923132194519043, 0.9843373889923096, 0.888335313129425, 0.823376679801941, 0.7629571042060852, 0.6896807415485382, 0.6221660990715027, 0.5733565196037292, 0.5419945928573608, 0.5191387284755706, 0.5095528283834457, 0.5087043375968933, 0.4949536618709564, 0.49743776283264163, 0.49274704637527467, 0.48438622064590453, 0.4795648615837097, 0.4850666898727417, 0.48112829194068907, 0.4803274715423584, 0.4804862366914749, 0.4801722486257553, 0.48633647170066835, 0.47880381469726563, 0.4824676710367203, 0.4765771726131439, 0.47922026493549347, 0.47823499948978426, 0.4778602351665497, 0.4808766175031662, 0.48095693960189817, 0.47610819721221925, 0.4794709888935089, 0.47481268396377563, 0.4759859416723251, 0.47462752690315246, 0.48058524626009164, 0.4756422427177429, 0.46910205149650575, 0.47475676488280294, 0.46731945350170134, 0.4720800220966339, 0.47617623579502105, 0.47055441942214965, 0.4815250439763069, 0.47236303317546846, 0.4720517207622528, 0.47185015497207644, 0.4773656021118164, 0.4732771725654602, 0.46767594764232634, 0.4745804940223694, 0.47159848346710204, 0.4702768645763397, 0.4711967253565788, 0.47402406783103945, 0.47362635761499405, 0.4685262858390808, 0.47555358171463014, 0.46932405495643614, 0.47357024450302126, 0.4714365583658218, 0.4726973157644272, 0.4682588846206665, 0.46936314315795896, 0.47537624220848085, 0.4715268637418747, 0.4663024564743042, 0.4690406922340393, 0.47258513977527616, 0.46653701763153077, 0.46928979868888854, 0.46902607884407044, 0.46521984255313875, 0.46160960042476656, 0.46465722784996033, 0.46606836647987365, 0.4671881468772888, 0.46552563853263856, 0.4682653615474701, 0.46549516159296034, 0.46245922541618345, 0.4639851933479309, 0.47197559330463407, 0.4669034992694855, 0.46793583605289457, 0.4637194360017777, 0.46892402386665344, 0.46454860219955446, 0.46284273904561996, 0.46199004163742063, 0.4680205914258957, 0.4628295825242996, 0.46243487212881446, 0.4575630754470825, 0.4575789396703243, 0.4618867224693298, 0.46275471720695494, 0.46761409230232237, 0.4646399435520172, 0.46107262477874755, 0.4627788953661919, 0.45282274050712584, 0.4542008066654205, 0.45589866514205935, 0.46410909007787704, 0.4608241473197937, 0.4578307390213013, 0.46150883564949036, 0.45769484333992005, 0.4582510160446167, 0.4588984333515167, 0.45850644698143006, 0.4545749282836914, 0.4567399115085602, 0.45585275440216066, 0.4558799756884575, 0.4561552851676941, 0.4543968320608139, 0.45680359563827516], 'accuracy': [0.1776, 0.2309, 0.2933, 0.3853, 0.4069, 0.4114, 0.4302, 0.4317, 0.4472, 0.4722, 0.4977, 0.5144, 0.5197, 0.5125, 0.5162, 0.5236, 0.5179, 0.5204, 0.5206, 0.5135, 0.5177, 0.5155, 0.5203, 0.5217, 0.5161, 0.5209, 0.5199, 0.53, 0.5562, 0.5924, 0.6475, 0.6986, 0.7336, 0.7487, 0.7621, 0.7634, 0.7722, 0.773, 0.7794, 0.7783, 0.7799, 0.7782, 0.7803, 0.7831, 0.7833, 0.7895, 0.788, 0.7864, 0.7902, 0.7865, 0.7861, 0.7839, 0.7881, 0.7874, 0.7908, 0.7913, 0.79, 0.7875, 0.7884, 0.7875, 0.7849, 0.7927, 0.7912, 0.7939, 0.7914, 0.7902, 0.7904, 0.7926, 0.7924, 0.7924, 0.794, 0.7941, 0.792, 0.7946, 0.7917, 0.795, 0.7914, 0.7947, 0.7938, 0.7916, 0.7975, 0.7966, 0.7929, 0.796, 0.7974, 0.7968, 0.795, 0.7973, 0.7957, 0.7983, 0.7987, 0.7991, 0.7979, 0.7973, 0.7938, 0.8018, 0.8008, 0.7987, 0.7995, 0.8003, 0.799, 0.7958, 0.7967, 0.8012, 0.8035, 0.7996, 0.799, 0.8034, 0.8008, 0.8007, 0.8035, 0.8024, 0.7992, 0.8026, 0.8025, 0.8035, 0.8029, 0.8008, 0.8064, 0.8037, 0.8034, 0.8049, 0.8039, 0.8039, 0.8087, 0.8058, 0.8062, 0.8009, 0.8039, 0.8063, 0.8067, 0.8056, 0.805, 0.8083, 0.8055, 0.806, 0.805, 0.8038, 0.8056, 0.8027, 0.807, 0.8095, 0.8061, 0.8088, 0.8067, 0.8075, 0.8077, 0.8099, 0.8077, 0.8104]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvxHFnodE-3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('my_new_trained_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuQ1mkdwE-3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBmVLmeLE-3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_results[0])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGPMYYjkE-3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl1xoakrE-3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "39cfffc8-980a-4321-88f4-79d5f1c9b695"
      },
      "source": [
        "k"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'hallway'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOIL2OmHE-30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1acc817d-7fd6-4767-eeda-ae678fec0f26"
      },
      "source": [
        "pred_results[0][val_max]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6DrvPQsE-31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d1fbb0f3-c3b6-4794-a8da-fe16b8c87434"
      },
      "source": [
        "# NOW WE'LL TEST THE MODEL WITH OUR VERY OWN STORY\n",
        "#NOTE: As the model has been trained on the vocab of just 38 words, we'll have to create the story with the words in vocab\n",
        "\n",
        "vocab"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'Where',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'garden',\n",
              " 'hallway',\n",
              " 'is',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'moved',\n",
              " 'office',\n",
              " 'the',\n",
              " 'to',\n",
              " 'travelled',\n",
              " 'went'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_AB7YWFE-33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXAMPLE 1\n",
        "my_story = \"John travelled to the hallway . Mary journeyed to the bedroom . John moved to the office .\"\n",
        "my_ques = \"Where is John ?\""
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZgUinANE-35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(), my_ques.split(), 'office')]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm6E95pXE-36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7bdc7aa7-2ebb-4fe2-8e27-584b4c7061b5"
      },
      "source": [
        "mydata"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['John',\n",
              "   'travelled',\n",
              "   'to',\n",
              "   'the',\n",
              "   'hallway',\n",
              "   '.',\n",
              "   'Mary',\n",
              "   'journeyed',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bedroom',\n",
              "   '.',\n",
              "   'John',\n",
              "   'moved',\n",
              "   'to',\n",
              "   'the',\n",
              "   'office',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'John', '?'],\n",
              "  'office')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07hcm43JE-37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6vcf287E-38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_ans = model.predict(([my_story, my_ques]))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1iNcWmdE-39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_ans)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyTi7p-fE-3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88326e0b-6bfb-4b14-8553-6b45dbd87cb8"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_ans[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  office\n",
            "Probability of certainty was:  0.9999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngqf7bJ7E-4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60ea0762-df88-4eb5-f769-e56ff7da428b"
      },
      "source": [
        "pred_ans.argsort()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  0,  8, 17, 12, 18, 14,  3, 19, 16,  2,  9, 10, 15, 13, 20,\n",
              "        21,  6,  1, 11,  5,  7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTVKYzz2E-4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "49d796ab-7074-4874-de14-862287853a89"
      },
      "source": [
        "for val_max in pred_ans.argsort()[0][-5:]:\n",
        "    for key, val in tokenizer.word_index.items():\n",
        "        if val == val_max:\n",
        "            k = key\n",
        "    print(\"Predicted answer is: \", k)\n",
        "    print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  kitchen\n",
            "Probability of certainty was:  1.7761385e-08\n",
            "Predicted answer is:  bathroom\n",
            "Probability of certainty was:  4.421059e-08\n",
            "Predicted answer is:  garden\n",
            "Probability of certainty was:  4.4512998e-08\n",
            "Predicted answer is:  bedroom\n",
            "Probability of certainty was:  6.3033625e-08\n",
            "Predicted answer is:  office\n",
            "Probability of certainty was:  0.9999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWB2CQGhE-4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9010456a-f55e-40d0-f6d1-7cd98e5aa8a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56eCNLDNZyqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/gdrive/My Drive/trained_model.h5')"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPw3MupasOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "867fe033-4f44-4083-aa28-e3f7aba506dc"
      },
      "source": [
        "vocab"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " '?',\n",
              " 'Daniel',\n",
              " 'John',\n",
              " 'Mary',\n",
              " 'Sandra',\n",
              " 'Where',\n",
              " 'back',\n",
              " 'bathroom',\n",
              " 'bedroom',\n",
              " 'garden',\n",
              " 'hallway',\n",
              " 'is',\n",
              " 'journeyed',\n",
              " 'kitchen',\n",
              " 'moved',\n",
              " 'office',\n",
              " 'the',\n",
              " 'to',\n",
              " 'travelled',\n",
              " 'went'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C94fbzJeaDje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXAMPLE 2\n",
        "my_story = \"Daniel journeyed to the Kitchen . John went to the bedroom . John travelled to the office . Daniel went to the garden . Sandra moved back to the Kitchen .\"\n",
        "my_ques = \"Where is Daniel ?\""
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmcyArzRd7bt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(), my_ques.split(), 'garden')]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sYCNtw9d_Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvk7N3dSeC_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_ans = model.predict(([my_story, my_ques]))"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuSDhAHeeIv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_ans)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_iwRY4keKjZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "521bac90-10b5-4a4c-8a57-7d3a83300dcd"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_ans[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  garden\n",
            "Probability of certainty was:  0.9999995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhKNxeXPeNRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "27eae376-84c7-4cb9-cebc-0d181239f914"
      },
      "source": [
        "for val_max in pred_ans.argsort()[0][-5:]:\n",
        "    for key, val in tokenizer.word_index.items():\n",
        "        if val == val_max:\n",
        "            k = key\n",
        "    print(\"Predicted answer is: \", k)\n",
        "    print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  bathroom\n",
            "Probability of certainty was:  2.0406397e-09\n",
            "Predicted answer is:  office\n",
            "Probability of certainty was:  1.0415498e-08\n",
            "Predicted answer is:  hallway\n",
            "Probability of certainty was:  9.974871e-08\n",
            "Predicted answer is:  kitchen\n",
            "Probability of certainty was:  3.6766e-07\n",
            "Predicted answer is:  garden\n",
            "Probability of certainty was:  0.9999995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExUvHhVFeoMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model got confused here."
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfqlTt1ey4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXAMPLE 3\n",
        "my_story = \"Daniel journeyed to the Kitchen . John went to the bedroom . John travelled to the office . Daniel went to the garden . Sandra moved back to the Kitchen .\"\n",
        "my_ques = \"Where is John ?\""
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2wtFdpvfKU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mydata = [(my_story.split(), my_ques.split(), 'garden')]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkkxxiVXfPdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "78e3d6e3-1c3b-4297-8202-215c7e35260f"
      },
      "source": [
        "mydata"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Daniel',\n",
              "   'journeyed',\n",
              "   'to',\n",
              "   'the',\n",
              "   'Kitchen',\n",
              "   '.',\n",
              "   'John',\n",
              "   'went',\n",
              "   'to',\n",
              "   'the',\n",
              "   'bedroom',\n",
              "   '.',\n",
              "   'John',\n",
              "   'travelled',\n",
              "   'to',\n",
              "   'the',\n",
              "   'office',\n",
              "   '.',\n",
              "   'Daniel',\n",
              "   'went',\n",
              "   'to',\n",
              "   'the',\n",
              "   'garden',\n",
              "   '.',\n",
              "   'Sandra',\n",
              "   'moved',\n",
              "   'back',\n",
              "   'to',\n",
              "   'the',\n",
              "   'Kitchen',\n",
              "   '.'],\n",
              "  ['Where', 'is', 'John', '?'],\n",
              "  'garden')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLIvSaJfRWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_story,my_ques,my_ans = vectorize_stories(mydata)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMsACeXYfUcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_ans = model.predict(([my_story, my_ques]))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lBOPLswfXPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_max = np.argmax(pred_ans)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkOFGU5RfZVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e04ebc07-b654-40ca-e982-dcf6c3ecc47e"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_ans[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  bathroom\n",
            "Probability of certainty was:  0.27967918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOKl_ae9fbc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f2387f61-1079-4c81-d2a9-2cd290b47881"
      },
      "source": [
        "for val_max in pred_ans.argsort()[0][-5:]:\n",
        "    for key, val in tokenizer.word_index.items():\n",
        "        if val == val_max:\n",
        "            k = key\n",
        "    print(\"Predicted answer is: \", k)\n",
        "    print(\"Probability of certainty was: \", pred_ans[0][val_max])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted answer is:  kitchen\n",
            "Probability of certainty was:  0.078002304\n",
            "Predicted answer is:  office\n",
            "Probability of certainty was:  0.108335465\n",
            "Predicted answer is:  hallway\n",
            "Probability of certainty was:  0.19714738\n",
            "Predicted answer is:  garden\n",
            "Probability of certainty was:  0.27417806\n",
            "Predicted answer is:  bathroom\n",
            "Probability of certainty was:  0.27967918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RofvhdjLfePt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}